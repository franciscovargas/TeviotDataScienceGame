{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "import numpy as np\n",
    "import theano as th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LoG = np.array([[0, 1,0],\n",
    "                [1,-4,1],\n",
    "                [0, 1,0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arguments  of Convolution2D\n",
    "\n",
    "* nb_filter: Number of convolution filters to use.\n",
    "* nb_row: Number of rows in the convolution kernel.\n",
    "* nb_col: Number of columns in the convolution kernel.\n",
    "* init: name of initialization function for the weights of the layer (see initializations), or alternatively, Theano * function to use for weights initialization. This parameter is only relevant if you don't pass a weights argument.\n",
    "* activation: name of activation function to use (see activations), or alternatively, elementwise Theano function. If you * don't specify anything, no activation is applied (ie. \"linear\" activation: a(x) = x).\n",
    "* weights: list of numpy arrays to set as initial weights.\n",
    "* border_mode: 'valid' or 'same'.\n",
    "* subsample: tuple of length 2. Factor by which to subsample output. Also called strides elsewhere.\n",
    "* W_regularizer: instance of WeightRegularizer (eg. L1 or L2 regularization), applied to the main weights matrix.\n",
    "* b_regularizer: instance of WeightRegularizer, applied to the bias.\n",
    "* activity_regularizer: instance of ActivityRegularizer, applied to the network output.\n",
    "* W_constraint: instance of the constraints module (eg. maxnorm, nonneg), applied to the main weights matrix.\n",
    "* b_constraint: instance of the constraints module, applied to the bias.\n",
    "* dim_ordering: 'th' or 'tf'. In 'th' mode, the channels dimension (the depth) is at index 1, in 'tf' mode is it at index 3. It defaults to the image_dim_ordering value found in your Keras config file at ~/.keras/keras.json. If you never set it, then it will be \"th\".\n",
    "* bias: whether to include a bias (i.e. make the layer affine rather than linear).\n",
    "\n",
    "### Input shape\n",
    "\n",
    "4D tensor with shape: (samples, channels, rows, cols) if dim_ordering='th' or 4D tensor with shape: (samples, rows, cols, channels) if dim_ordering='tf'.\n",
    "\n",
    "### Output shape\n",
    "\n",
    "4D tensor with shape: (samples, nb_filter, new_rows, new_cols) if dim_ordering='th' or 4D tensor with shape: (samples, new_rows, new_cols, nb_filter) if dim_ordering='tf'. rows and cols values might have changed due to padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 0,  1,  0],\n",
       "         [ 1, -4,  1],\n",
       "         [ 0,  1,  0]],\n",
       "\n",
       "        [[ 0,  1,  0],\n",
       "         [ 1, -4,  1],\n",
       "         [ 0,  1,  0]],\n",
       "\n",
       "        [[ 0,  1,  0],\n",
       "         [ 1, -4,  1],\n",
       "         [ 0,  1,  0]]],\n",
       "\n",
       "\n",
       "       [[[ 0,  1,  0],\n",
       "         [ 1, -4,  1],\n",
       "         [ 0,  1,  0]],\n",
       "\n",
       "        [[ 0,  1,  0],\n",
       "         [ 1, -4,  1],\n",
       "         [ 0,  1,  0]],\n",
       "\n",
       "        [[ 0,  1,  0],\n",
       "         [ 1, -4,  1],\n",
       "         [ 0,  1,  0]]],\n",
       "\n",
       "\n",
       "       [[[ 0,  1,  0],\n",
       "         [ 1, -4,  1],\n",
       "         [ 0,  1,  0]],\n",
       "\n",
       "        [[ 0,  1,  0],\n",
       "         [ 1, -4,  1],\n",
       "         [ 0,  1,  0]],\n",
       "\n",
       "        [[ 0,  1,  0],\n",
       "         [ 1, -4,  1],\n",
       "         [ 0,  1,  0]]]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight = np.array([LoG for c in range(3)])\n",
    "# weights.swapaxes(0,-1)\n",
    "weights = np.array([weight for c in range(3)])\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CNN Layer signature\n",
    "Convolution1D(nb_filter,\n",
    "              filter_length,\n",
    "              init='uniform',\n",
    "              activation='linear', \n",
    "              weights=None,\n",
    "              border_mode='valid',\n",
    "              subsample_length=1,\n",
    "              W_regularizer=None,\n",
    "              b_regularizer=None,\n",
    "              activity_regularizer=None,\n",
    "              W_constraint=None, b_constraint=None, bias=True, input_dim=None, input_length=None)\n",
    "\"\"\"\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(nb_filter=3,border_mode='valid',nb_row=3,nb_col=3 , input_shape=(3,64,64),\n",
    "                        weights=[weights, np.array([0,0,0]) ]) )\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(nb_filter=32,border_mode='valid', nb_row=3, nb_col=3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# model.add(Convolution2D(nb_filter=1, nb_row=2, nb_col=2))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "# MLP\n",
    "model.add(Dense(200))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#Classification Layer\n",
    "model.add(Dense(4))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compile model\n",
    "sgd = SGD(lr=0.5)\n",
    "\n",
    "\n",
    "\n",
    "model.compile(optimizer=sgd,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cPickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainX = pkl.load(open(\"../data/pkl/trainX.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainX=trainX.transpose(0,3,1,2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainY = pkl.load(open(\"../data/pkl/trainY.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/19\n",
      "8000/8000 [==============================] - 13s - loss: 1.2286 - acc: 0.4604    \n",
      "Epoch 2/19\n",
      "8000/8000 [==============================] - 13s - loss: 1.1049 - acc: 0.5301    \n",
      "Epoch 3/19\n",
      "8000/8000 [==============================] - 13s - loss: 1.0282 - acc: 0.5715    \n",
      "Epoch 4/19\n",
      "8000/8000 [==============================] - 13s - loss: 1.0057 - acc: 0.5789    \n",
      "Epoch 5/19\n",
      "8000/8000 [==============================] - 13s - loss: 0.9637 - acc: 0.5976    \n",
      "Epoch 6/19\n",
      "8000/8000 [==============================] - 13s - loss: 0.9679 - acc: 0.5941    \n",
      "Epoch 7/19\n",
      "8000/8000 [==============================] - 13s - loss: 0.8864 - acc: 0.6367    \n",
      "Epoch 8/19\n",
      "8000/8000 [==============================] - 13s - loss: 0.8735 - acc: 0.6494    \n",
      "Epoch 9/19\n",
      "8000/8000 [==============================] - 13s - loss: 0.8102 - acc: 0.6741    \n",
      "Epoch 10/19\n",
      "8000/8000 [==============================] - 13s - loss: 0.7819 - acc: 0.6831    \n",
      "Epoch 11/19\n",
      "8000/8000 [==============================] - 13s - loss: 0.9129 - acc: 0.6279    \n",
      "Epoch 12/19\n",
      "8000/8000 [==============================] - 13s - loss: 0.8866 - acc: 0.6300    \n",
      "Epoch 13/19\n",
      "8000/8000 [==============================] - 13s - loss: 0.7558 - acc: 0.6990    \n",
      "Epoch 14/19\n",
      "8000/8000 [==============================] - 13s - loss: 0.6831 - acc: 0.7315    \n",
      "Epoch 15/19\n",
      "8000/8000 [==============================] - 13s - loss: 0.6472 - acc: 0.7472    \n",
      "Epoch 16/19\n",
      "8000/8000 [==============================] - 13s - loss: 0.5386 - acc: 0.7903    \n",
      "Epoch 17/19\n",
      "8000/8000 [==============================] - 13s - loss: 0.5024 - acc: 0.8061    \n",
      "Epoch 18/19\n",
      "8000/8000 [==============================] - 13s - loss: 0.4265 - acc: 0.8358    \n",
      "Epoch 19/19\n",
      "8000/8000 [==============================] - 14s - loss: 0.4329 - acc: 0.8397    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x3f98ad0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trainX, to_categorical(trainY-1,4) , batch_size=100, nb_epoch=19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"../data/pkl/model87log.pkl\", \"wb\") as f:\n",
    "    pkl.dump(model,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "8000/8000 [==============================] - 13s - loss: 0.3749 - acc: 0.8666    \n",
      "Epoch 2/4\n",
      "8000/8000 [==============================] - 13s - loss: 0.3653 - acc: 0.8660    \n",
      "Epoch 3/4\n",
      "8000/8000 [==============================] - 13s - loss: 0.4183 - acc: 0.8492    \n",
      "Epoch 4/4\n",
      "8000/8000 [==============================] - 13s - loss: 0.3299 - acc: 0.8725    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x51d8e90>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trainX, to_categorical(trainY-1,4) , batch_size=100, nb_epoch=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
